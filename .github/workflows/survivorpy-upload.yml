name: Upload Survivor Data to S3

on:
  workflow_dispatch:
  schedule:
    - cron: '0 8 * * 6'

jobs:
  upload_to_s3:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up R
        uses: r-lib/actions/setup-r@v2

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libcurl4-openssl-dev libssl-dev libxml2-dev cmake make g++

      - name: Set R library path and cache packages
        uses: actions/cache@v3
        with:
          path: ~/.R/library
          key: ${{ runner.os }}-r-library-${{ hashFiles('data_fetching/convert_survivor_to_parquet.R') }}
          restore-keys: |
            ${{ runner.os }}-r-library-

      - name: Install R packages
        run: |
          mkdir -p ~/.R/library
          echo 'R_LIBS_USER="~/.R/library"' >> ~/.Renviron
          Rscript -e 'install.packages(c("aws.s3", "jsonlite", "remotes", "arrow"), repos="https://cloud.r-project.org", lib="~/.R/library")'
          Rscript -e 'remotes::install_github("doehm/survivoR", lib="~/.R/library")'
        env:
          GITHUB_PAT: ${{ secrets.GH_PAT }}

      - name: Run R script to upload data to S3
        run: |
          Rscript -e '.libPaths("~/.R/library"); source("data_fetching/convert_survivor_to_parquet.R")'
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}
